{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlxDhFKjVVaMcSAjvsgHOb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JIANSO/jianso/blob/main/1_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_%EB%B0%8F_%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터분석"
      ],
      "metadata": {
        "id": "zNOp_b7WgY9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이번 장은 데이터를 살펴보기 위해 불러오고 내용을 파악하는 과정입니다.\n",
        "### 데이터에 대해 이미 파악하신 상태라면 이번 장을 건너뛰셔도 좋습니다."
      ],
      "metadata": {
        "id": "JLMMCQABgeYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 목차\n",
        "1. 데이터 불러오기\n",
        "1. Pandas 사용하기\n",
        "1. 데이터 소개\n",
        "1. 사용할 데이터 선택\n",
        "1. 데이터 정리\n",
        "1. 데이터 통합"
      ],
      "metadata": {
        "id": "fly4sjU0gWoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 데이터 불러오기"
      ],
      "metadata": {
        "id": "enfSH40HgUC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "yFHJ1wCtgRu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습이 진행되는 동안 numpy, pandas 라이브러리를 자주 사용할 것입니다.  \n",
        "또한 KT AIDU를 통해 데이터를 불러오기 위한 라이브러리를 추가로 사용해야 합니다.  \n",
        "파이썬에서 라이브러리를 불러오기 위해 다음의 4개 라이브러리를 import 할 것입니다.  \n",
        "1. aicentro.session.Session\n",
        "1. aicentro.framework.keras.Keras\n",
        "1. numpy\n",
        "1. pandas"
      ],
      "metadata": {
        "id": "Iq7PvzRDgPnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드를 통해 1번과 2번 라이브러리를 import 해보겠습니다."
      ],
      "metadata": {
        "id": "tfqFQa6KgjR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aicentro.session import Session\n",
        "from aicentro.framework.keras import Keras as AiduFrm\n",
        "print(\"--에러 메시지가 나타나지 않았다면 정상적으로 import된 것입니다.--\")"
      ],
      "metadata": {
        "id": "k6GiW72agl1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 3번과 4번 라이브러리를 import 해봅시다."
      ],
      "metadata": {
        "id": "YcrkckxHgoTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(실습 1) 남은 2개 라이브러리를 불러옵니다."
      ],
      "metadata": {
        "id": "JeS6UsetgsXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9hkUVLiggtXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 이번 장에 필요한 라이브러리들을 모두 import 했습니다."
      ],
      "metadata": {
        "id": "owZJAa5Rgu3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. 데이터 불러오기"
      ],
      "metadata": {
        "id": "Hq45BfzEgxIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음으로 우리가 사용할 데이터를 불러올 것입니다.  \n",
        "다른 방법으로 데이터를 불러올 수도 있지만 AIDU에서는 다음과 같은 방법을 제공합니다.  \n",
        "아래 코드를 실행해봅시다."
      ],
      "metadata": {
        "id": "OPVb7MXtgyed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aidu_session = Session(verify=False)\n",
        "aidu_framework = AiduFrm(session=aidu_session)\n",
        "data_jan = pd.read_csv(\"air_data_01.csv\", header=0, encoding='cp949')"
      ],
      "metadata": {
        "id": "fZectlmXg0CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이처럼 파일의 위치를 알면 간단하게 데이터를 불러올 수 있습니다.\n",
        "위의 코드를 통해 아실 수 있겠지만 우리가 사용할 데이터는 11개 파일로 \"airmap/air_data_월.csv\"로 저장되어 나뉘어 있습니다.\n",
        "이제 2월의 데이터를 불러옵시다."
      ],
      "metadata": {
        "id": "GdJQFBmVg2I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(실습 2) 2월의 데이터를 불러옵니다."
      ],
      "metadata": {
        "id": "28rem39ig3jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : aidu_session과 aidu_framework는 다시 불러오지 않아도 됩니다.\n",
        "data_feb = pd.read_csv(\"air_data_02.csv\", header=0, encoding='cp949')"
      ],
      "metadata": {
        "id": "x0gQC2ZqhBFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "간단하게 변수명만 호출하면 해당 변수를 화면에 표출시킬 수 있습니다."
      ],
      "metadata": {
        "id": "_ApdkC88hDwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1월의 데이터\n",
        "data_jan"
      ],
      "metadata": {
        "id": "oO3HncZthHIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "왼쪽 아래 행의 수와 열의 수가 표시되는 것을 볼 수 있습니다.  \n",
        "이러한 정보를 더 자세히 보기 위해선 DataFrame의 info() 기능을 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "2UPSYe1thKQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_jan.info()"
      ],
      "metadata": {
        "id": "IEmSY_9ohL_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리가 불러온 데이터의 정보를 간략하게 확인할 수 있습니다.\n",
        "각 열별 데이터의 타입, 데이터의 크기 등이 표시됩니다."
      ],
      "metadata": {
        "id": "0Z9u62OAhNuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Pandas 사용하기"
      ],
      "metadata": {
        "id": "qEt8VLIshPKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. Pandas에 대해"
      ],
      "metadata": {
        "id": "qQMp_Fx9hQaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas는 데이터를 여러 형태로부터 불러오고 필요한 열, 행을 추출, 그룹화, 정렬, 계산하기 위한 라이브러리입니다."
      ],
      "metadata": {
        "id": "bmP7qZnMhUMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Series와 DataFrame이라는 형태를 갖고 있는데 Series를 표에서의 하나의 열, DataFrame을 Series가 모인 표 자체라고 생각하시면 쉽습니다.  \n",
        "특히 tail(), head() 함수를 쓰면 데이터를 간단하게 파악하기 좋습니다. 기본은 앞, 뒤에서 5행을 보여주고 숫자를 정해주면 더 많은 데이터를 표출할 수도 있습니다.  \n",
        "1을 통해 우리가 가져온 데이터는 DataFrame의 형식을 갖습니다."
      ],
      "metadata": {
        "id": "l0cq_xvnhXGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_jan.head(3)"
      ],
      "metadata": {
        "id": "qCRkdeZehaVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 3) 1월 데이터의 뒤 9행을 표시해봅시다."
      ],
      "metadata": {
        "id": "oXUtg-uqhcdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : head()와 다른 것은 이름 뿐입니다.\n",
        "data_jan.tail(3)"
      ],
      "metadata": {
        "id": "6aVfakJ_hheE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. 데이터 둘러보기"
      ],
      "metadata": {
        "id": "h5kuE3bZii3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 살펴보면 각 행의 특징을 알 수 있습니다.  \n",
        "가령 1번 행은 전체 데이터에서 늘 1인 것처럼 보입니다. 이것은 3번과 4번, 5번 데이터도 마찬가지입니다.  \n",
        "정말 그런지 확인해봅시다."
      ],
      "metadata": {
        "id": "jvzngk8uhkhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 4) 데이터의 여러 열들 중 모든 행에서 같은 값만 갖는 열이 무엇인지 살펴봅시다."
      ],
      "metadata": {
        "id": "FBKr1yifhm94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : 의심이 가는 열이 있으면 Series의 함수 중 unique()를 사용할 수 있습니다.\n",
        "# Hint : DataFrame에서 Series를 추출해봅니다.\n",
        "data_jan['6'].unique()"
      ],
      "metadata": {
        "id": "-Jo1d2Dahn4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "잘 분석하셨다면 같은 값만 갖는 몇 개의 열을 발견하셨을 겁니다.  \n",
        "특히 6번 열을 확인하시면 3개의 값만 가지고 있음을 아실 수 있을 겁니다.  \n",
        "이 3개의 데이터는 초미세먼지, 온도, 습도의 구분입니다."
      ],
      "metadata": {
        "id": "WnB31XE_hqWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 중에서 습도의 데이터만 따로 확인하려면 아래의 방법을 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "-w5CJjAch3HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : 각각의 변수에 값이 어떻게 저장되는지 확인해보세요.\n",
        "cond_dust = data_jan['6'] == '습도'\n",
        "data_jan[cond_dust]"
      ],
      "metadata": {
        "id": "0KVOJce2h4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번엔 온도 데이터만 따로 확인해봅시다."
      ],
      "metadata": {
        "id": "ys3NYpech-dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : 위의 방법을 사용하되 변수를 알맞게 지정해봅시다.\n",
        "cond_temp = data_jan['6'] == '온도'\n",
        "data_jan[cond_temp]"
      ],
      "metadata": {
        "id": "q3EXgutKh_a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 18, 19번 열을 보면 대부분 값이 NaN인 것을 알 수 있습니다.  \n",
        "이 값은 컴퓨터에서 해당 열이 숫자를 저장하기로 한 곳에서 숫자가 아닌 값을 표기하는 방식입니다.  \n",
        "pandas DataFrame에서는 이렇게 NaN으로 가득찬 열을 쉽게 제거할 수 있습니다."
      ],
      "metadata": {
        "id": "E5W3UMEeiBd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 6) NaN으로 가득찬 열을 제외하고 데이터를 다시 지정해봅시다."
      ],
      "metadata": {
        "id": "SAFIPv1aiECU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : pandas 중 dropna를 찾아보세요.\n",
        "# Hint : 데이터가 다시 잘 지정되었는지 확인해보세요.\n",
        "data_jan_dropped = data_jan.dropna(how='all', axis='columns')\n",
        "data_jan_dropped.head(3)"
      ],
      "metadata": {
        "id": "6UHOBAeyiFKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터 소개"
      ],
      "metadata": {
        "id": "cqu7dfE9iI1l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-eRq0FSsitiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. 데이터 설명"
      ],
      "metadata": {
        "id": "tJkT6yJQiJ7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제까지는 데이터를 다루기 위한 기본 툴의 사용법을 알아보았습니다.  \n",
        "아마 각 데이터가 어떤 내용인지 모르는 상태에서 데이터를 다루는 게 복잡하게 느껴지셨을 수도 있습니다.  \n",
        "또한 데이터를 간단히 정돈하면서 다른 열들이 의미가 있을지 궁금하셨을 수도 있습니다.  \n",
        "이제 각 열의 의미를 알아봅시다."
      ],
      "metadata": {
        "id": "k-VJLRAfiLDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 전에 데이터를 보기 쉽게 다시 표출해 보죠."
      ],
      "metadata": {
        "id": "bIWdtFH9iMb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_jan.head(3)"
      ],
      "metadata": {
        "id": "iIn6PJYwiN3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리가 사용할 데이터는 제주도의 총 62개 데이터 수집 지점에서 수집한 공기질 데이터입니다.  \n",
        "총 20개의 열이 있는데 차례로\n",
        "- **0** : 수집 시간. 5분 간격으로 데이터가 정리되어 있습니다.\n",
        "- **1** : 데이터소스\n",
        "- **2** : 서비스 지역\n",
        "- **3** : 측정장비의 번호\n",
        "- **4** : 데이터의 출처\n",
        "- **5** : 데이터의 종류\n",
        "- **6** : 데이터의 구분\n",
        "- **7** : 5분 간격 중 최소값.\n",
        "- **8** : 5분 간격 중 최대값.\n",
        "- **9** : 5분 간격 중 평균값\n",
        "- **10** : 5분 간격 중 합.\n",
        "- **11** : 5분 간격 사이 수집 횟수.\n",
        "- **12** : 표준편차.\n",
        "- **13** : 분산.\n",
        "- **14** : 측정 주기.\n",
        "- **15** : 날짜\n",
        "- **16** : 시간\n",
        "- **17** : 분\n",
        "- **18** : 수집 담당자\n",
        "- **19** : 비고"
      ],
      "metadata": {
        "id": "BVgNfymAiP0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "위와 같은 내용을 담고 있습니다.\n",
        "또한 각 행의 0열을 보시면 8시간 간격으로 데이터가 구분되어 있는 것을 확인하실 수 있으실 겁니다.\n",
        "이런 데이터가 월별로 1월부터 11월까지 나뉘어 air_data_01.csv ~ air_data_11.csv에 각각 저장되어 있고 우리는 이 데이터들을 바탕으로 다음 한 달간의 데이터를 예측하는 AI를 학습할 것입니다."
      ],
      "metadata": {
        "id": "erTftXCyiREX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 사용할 데이터 선택"
      ],
      "metadata": {
        "id": "B6FTRTmfiSOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. 데이터 선택"
      ],
      "metadata": {
        "id": "9EwvfrloiTdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사실 아무 데이터나 사용해도 좋습니다.\n",
        "하지만 우리는 같은 해 1월부터 10월까지의 데이터로 11월의 데이터를 예측한다는 점을 고려하면 월별로 데이터의 경향이 크게 바뀌는 온도, 습도를 학습시키긴 어려워보입니다.\n",
        "이런 데이터를 예측하려면 연 주기성을 확보하기 위해 1년 이상의 데이터가 필요할 것입니다.\n",
        "따라서 월별 변화가 상대적으로 적을 것으로 예상되는 초미세먼지로 학습 대상을 결정하는 것이 좋아 보입니다.\n",
        "하지만 이것이 기온, 습도로는 학습을 진행시킬 수 없다는 의미는 아닙니다.\n",
        "1년이 안 되는 데이터지만 기온, 습도로 학습을 진행시킬 수도 있고 우리의 목표는 학습의 과정을 경험해 보는 것입니다.\n",
        "해설은 초미세먼지 데이터를 사용할 것입니다.\n",
        "하지만 실습 과정에서 여러분이 여러분만의 데이터를 사용하셔도 문제될 일은 없을 것입니다.\n",
        "이제 각자 학습을 위해, 적절한 데이터를 선택해보세요."
      ],
      "metadata": {
        "id": "sNtAHk4ViU6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 7) 이제 데이터를 선택해보겠습니다. 9월의 데이터를 불러와 초미세먼지, 온도, 습도 중 여러분이 학습하고자 하는 데이터를 살펴보세요."
      ],
      "metadata": {
        "id": "ftuC1elWibXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : 이번 장의 과정을 차례로 살펴보세요.\n",
        "data_sep = pd.read_csv(\"air_data_09.csv\", header=0, encoding='cp949')\n",
        "\n",
        "data_sep_dropped = data_sep.dropna(how='all', axis='columns')\n",
        "\n",
        "cond_dust = data_sep_dropped['6'] == '습도'\n",
        "\n",
        "data_sep_dropped[cond_dust].head(5)"
      ],
      "metadata": {
        "id": "cDhOeyMvictK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. 데이터 줄이기"
      ],
      "metadata": {
        "id": "WuTDsgpsiukU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "불러온 데이터를 보면 NaN과 같은 사용하지 않을 데이터도 있고 0열과 15, 16, 17열과 같이 같은 내용을 포함하는 경우, 전체 행에서 동일한 값을 갖는 1, 2, 4, 5와 같은 열도 있습니다.  \n",
        "그리고 사용할 데이터로도 최소값, 최대값, 평균, 분산, 합, 표준편차 등과 같이 많은 종류가 있습니다.  \n",
        "이제 우리가 사용할 데이터만 찾아봅시다."
      ],
      "metadata": {
        "id": "CDjiYiMZiv2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrame에서 다음의 방법으로 원하는 열만 고를 수 있습니다."
      ],
      "metadata": {
        "id": "o37kY3Wtiw--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_jan[['3', '6', '8']]"
      ],
      "metadata": {
        "id": "4-GlpQiCiyJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "혹은 DataFrame의 drop() 기능을 사용하면 사용하지 않을 열을 제외시킬 수 있습니다."
      ],
      "metadata": {
        "id": "gsYz_pz4kIwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_jan.drop(data_jan.columns[[4, 5, 14]], axis='columns')"
      ],
      "metadata": {
        "id": "z9I73TsnkKDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 앞서 dropna()를 사용하기도 했습니다.  "
      ],
      "metadata": {
        "id": "-0fMOxshkOES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기억할 것은, 기본적으로 이 기능들이 저장된 DataFrame에 변형을 일으키지 않는다는 것입니다.  \n",
        "그래서 우리는 새 변수에 변형된 값을 저장해 사용해야 합니다.  \n",
        "이제 사용할 데이터만 추출해 봅시다."
      ],
      "metadata": {
        "id": "RsQjEXxLkPNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 실습에서는 측정 [장비의 번호, 데이터의 구분, 평균값, 날짜]의 4가지 데이터만 사용할 것입니다."
      ],
      "metadata": {
        "id": "svZLZsGEkRnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 8) 1월의 데이터 중 사용할 데이터만 추출해 다른 변수에 지정해 봅시다."
      ],
      "metadata": {
        "id": "P4jkaC8BkTyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : 열을 선택하는 방식, 제외하는 방식 모두 사용할 수 있습니다.\n",
        "data_jan_dropped = data_jan[['3', '6', '8', '15']]\n",
        "data_jan_dropped"
      ],
      "metadata": {
        "id": "IMcmOskdkWEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 데이터 정리"
      ],
      "metadata": {
        "id": "FLBizdd5kZZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. 데이터 구분하기"
      ],
      "metadata": {
        "id": "GSmhdK7NkbZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 앞 장에서 사용했던 방법으로 데이터의 종류에 맞게 서로 다른 변수에 데이터를 저장해 봅시다.  \n",
        "예를 들어 다음의 방법으로 초미세먼지 데이터를 구분할 수 있습니다."
      ],
      "metadata": {
        "id": "q9tf5hq4kcdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cond_dust = data_jan_dropped['6'] == '초미세먼지'\n",
        "data_jan_dust = data_jan_dropped[cond_dust]"
      ],
      "metadata": {
        "id": "vrM26B5ukeL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리가 8시간 단위의 데이터를 다루고 있다는 것을 생각해 봅시다.  \n",
        "3종류의 데이터, 하루에 3번씩, 62곳의 데이터를 11개월 가량 사용하면 17만 개가 넘는 방대한 데이터를 사용하게 됩니다.  \n",
        "따라서 저는 이 데이터를 아주 작게 줄여보겠습니다.  \n",
        "8시간 단위의 데이터를 1일 단위의 데이터로 바꾸고 데이터를 줄일 때는 중간값을 기준으로 사용해 보겠습니다.  \n",
        "groupby()를 사용해 그룹화할 열을 지정하고 median()을 사용해 중간값을 기준으로 그룹내 행이 합쳐지도록 하겠습니다.  \n",
        "이 때 측정 장비의 번호역시 중간값으로 합쳐지지 않도록 같이 그룹화합니다."
      ],
      "metadata": {
        "id": "rFevFzQbkg7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_jan_dust_day = data_jan_dust.groupby(['15', '3']).median()\n",
        "data_jan_dust_day.head(5)"
      ],
      "metadata": {
        "id": "RY8GEDVyknt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 데이터가 일 단위로 바뀌면서 행 번호 대신 날짜가 온 것을 볼 수 있습니다.\n",
        "다시 행 번호를 붙이려면 reset_index()를 사용합니다."
      ],
      "metadata": {
        "id": "AHRfBOx3kq2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_jan_dust_day = data_jan_dust_day.reset_index()\n",
        "data_jan_dust_day.head()"
      ],
      "metadata": {
        "id": "kdAszcCUkyyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "새로운 DataFrame을 선언해 저장하면 각 열의 이름을 편하게 입력할 수 있습니다.  \n",
        "이제 date는 수집 날짜, dev는 장비 번호, val은 중간값입니다."
      ],
      "metadata": {
        "id": "B2AUIgm1lHJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.DataFrame()"
      ],
      "metadata": {
        "id": "KHLlz_QAlKh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data['date'] = data_jan_dust_day['15']\n",
        "new_data['dev'] = data_jan_dust_day['3']\n",
        "new_data['val'] = data_jan_dust_day['8']\n",
        "new_data.head()"
      ],
      "metadata": {
        "id": "oNxgZqI1lLtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 이 작업을 2월 데이터에도 적용해봅시다."
      ],
      "metadata": {
        "id": "zG5yhTCslNf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 9) 2월의 데이터를 불러와 같은 방식으로 편집해봅시다"
      ],
      "metadata": {
        "id": "zUOCO7T7lPrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : 우선 데이터를 불러온 뒤 Step4의 내용을 반복하면 됩니다.\n",
        "data_feb = pd.read_csv(\"air_data_02.csv\", header=0, encoding='cp949')\n",
        "\n",
        "data_feb_dropped = data_feb[['3', '6', '8', '15']]\n",
        "\n",
        "cond_dust_feb = data_feb_dropped['6'] == '초미세먼지'\n",
        "data_feb_dust = data_feb_dropped[cond_dust_feb]\n",
        "\n",
        "data_feb_dust_day = data_feb_dust.groupby(['15', '3']).median()\n",
        "data_feb_dust_day = data_feb_dust_day.reset_index()\n",
        "\n",
        "feb_data = pd.DataFrame()\n",
        "feb_data['date'] = data_feb_dust_day['15']\n",
        "feb_data['dev'] = data_feb_dust_day['3']\n",
        "feb_data['val'] = data_feb_dust_day['8']\n",
        "feb_data.head()"
      ],
      "metadata": {
        "id": "aqBmSv_elREM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 데이터 통합"
      ],
      "metadata": {
        "id": "lDYB9pQXlbX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. 데이터 합치기"
      ],
      "metadata": {
        "id": "97olYo7VlcTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 두 데이터를 연결할 땐 pandas의 concat()을 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "F9njl3pFldfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concat_data = pd.concat([new_data, feb_data])\n",
        "concat_data.info()"
      ],
      "metadata": {
        "id": "4CLYajWulh5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 이 과정을 전체 1월~11월의 데이터에 적용해봅시다."
      ],
      "metadata": {
        "id": "WEDPga4vlkRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 10) 전체 데이터를 불러와 같은 방식으로 편집한 후 하나의 DataFrame(변수명 : result)로 합칩니다."
      ],
      "metadata": {
        "id": "-Ls9Bzm1llQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : 배열을 사용해 데이터를 불러오면 반복적으로 호출하기 쉽습니다.\n",
        "# result = pd.DataFrame()\n",
        "\n",
        "coloumns_we_need = ['3', '6', '8', '15']\n",
        "dust = '초미세먼지'\n",
        "\n",
        "result = pd.DataFrame()\n",
        "\n",
        "for i in range(1, 12):\n",
        "    print(\"data loading...\"+str(i))\n",
        "    data = pd.read_csv(\"air_data_\"+str(i).zfill(2)+\".csv\", header=0, encoding='cp949')\n",
        "    data_dropped = data[coloumns_we_need]\n",
        "    cond_dust = data_dropped['6'] == dust\n",
        "\n",
        "    data_dust = data_dropped[cond_dust]\n",
        "\n",
        "    data_dust_day = data_dust.groupby(['15', '3']).median()\n",
        "    data_dust_day = data_dust_day.reset_index()\n",
        "\n",
        "    new_df = pd.DataFrame()\n",
        "    new_df['date'] = data_dust_day['15']\n",
        "    new_df['dev'] = data_dust_day['3']\n",
        "    new_df['val'] = data_dust_day['8']\n",
        "\n",
        "    result = pd.concat([result, new_df])\n",
        "\n",
        "result.info()"
      ],
      "metadata": {
        "id": "T9Q4NDgdloTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "l6EKoU1Xlq7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리의 계획은 각 데이터를 장치 번호별로 나누어 저장하는 것입니다.  \n",
        "앞서 학습했던 내용들을 바탕으로 각각의 csv로 저장해보겠습니다.  \n",
        "pandas를 통해 csv로 저장하는 방법은 아래와 같습니다."
      ],
      "metadata": {
        "id": "4vN9wqXfl3J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_csv(\"data_concat.csv\",index=False)"
      ],
      "metadata": {
        "id": "vlXmdv9Vl5HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 장치 번호별, 1월부터 11월까지의 데이터를 저장합시다.\n",
        "이 내용은 실습으로 남기겠습니다."
      ],
      "metadata": {
        "id": "soG7pyD2l7I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (실습 11) 장치 번호별, 1월부터 10월까지 합쳐진 데이터를 저장합니다. 데이터는 data_장치번호.csv 로 저장하겠습니다."
      ],
      "metadata": {
        "id": "y2V7zKfXl86J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint : data_1.csv, data_2.csv, ...\n",
        "# Hint : unique()를 사용해 나온 배열을 사용하면 편리합니다.\n",
        "for item in result['dev'].unique():\n",
        "    cond_result = result['dev']==item\n",
        "    temp = result[cond_result]\n",
        "    temp.to_csv(\"data_\"+str(item)+\".csv\",index=False)"
      ],
      "metadata": {
        "id": "2O9II-qBl92k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}